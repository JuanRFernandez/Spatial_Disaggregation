{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import rc\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from zoomin_client import client\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "api_key = os.environ.get(\"DJANGO_API_Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "REPORT_PATH = os.path.join(cwd, \"..\", \"..\", \"reports\", \"04_D3.2_appendix\")\n",
    "DATA_PATH = os.path.join(cwd, \"..\", \"..\", \"data\", \"output\", \"api_data\")\n",
    "VAR_DF_PATH = os.path.join(cwd, \"..\", \"..\", \"data\", \"input\", \"raw\", \"vars_list_details_and_tags.xlsx\")\n",
    "SHP_PATH = os.path.join(cwd, \"..\", \"..\", \"data\", \"input\", \"processed\", \"shapefiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clm_related_vars = [\"annual mean mean temperature\",\n",
    "            \"annual mean precipitation\",\n",
    "            \"annual total precipitation\",\n",
    "            \"annual mean maximum temperature\",\n",
    "            \"annual mean minimum temperature\",\n",
    "            \"annual mean temperature cooling degree days\",\n",
    "            \"annual maximum temperature cooling degree days\",\n",
    "            \"annual minimum temperature cooling degree days\",\n",
    "            \"annual mean temperature heating degree days\",\n",
    "            \"annual maximum temperature heating degree days\",\n",
    "            \"annual minimum temperature heating degree days\",\n",
    "                    \"probability of a heatwave\",\n",
    "                   \"change in heatwave frequency\",\n",
    "                   \"probability of a coldwave\",\n",
    "                   \"change in coldwave frequency\",\n",
    "                   \"probability of a drought\",\n",
    "                   \"change in drought frequency\"\n",
    "           ]\n",
    "\n",
    "eucalc_transpor_related_data = [\"tra_vehicle-lifetime_new_freight_HDVL_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVL_CEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVL_PHEV-diesel\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVL_PHEV-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVL_ICE-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVL_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVL_ICE-gas\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVL_BEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_CEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_PHEV-diesel\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_PHEV-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_ICE-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_ICE-gas\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVM_BEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_CEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_PHEV-diesel\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_PHEV-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_ICE-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_ICE-gas\",\n",
    "\"tra_vehicle-lifetime_new_freight_HDVH_BEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_rail_CEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_rail_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_freight_aviation_BEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_aviation_ICE\",\n",
    "\"tra_vehicle-lifetime_new_freight_IWW_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_IWW_BEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_IWW_ICE\",\n",
    "\"tra_vehicle-lifetime_new_freight_marine_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_marine_BEV\",\n",
    "\"tra_vehicle-lifetime_new_freight_marine_ICE\",\n",
    "\"tra_vehicle-lifetime_new_passenger_LDV_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_passenger_LDV_ICE-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_passenger_LDV_ICE-gas\",\n",
    "\"tra_vehicle-lifetime_new_passenger_LDV_PHEV-diesel\",\n",
    "\"tra_vehicle-lifetime_new_passenger_LDV_PHEV-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_passenger_LDV_BEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_LDV_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_2W_ICE-gas\",\n",
    "\"tra_vehicle-lifetime_new_passenger_2W_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_passenger_2W_ICE-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_passenger_2W_BEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_2W_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_2W_PHEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_bus_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_passenger_bus_ICE-gasoline\",\n",
    "\"tra_vehicle-lifetime_new_passenger_bus_ICE-gas\",\n",
    "\"tra_vehicle-lifetime_new_passenger_bus_BEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_bus_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_bus_PHEV-diesel\",\n",
    "\"tra_vehicle-lifetime_new_passenger_metro-tram_CEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_rail_CEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_rail_FCEV\",\n",
    "\"tra_vehicle-lifetime_new_passenger_rail_ICE-diesel\",\n",
    "\"tra_vehicle-lifetime_new_passenger_aviation_ICE\",\n",
    "\"tra_vehicle-lifetime_new_passenger_aviation_BEV\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6388e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = pd.read_excel(VAR_DF_PATH, sheet_name=\"input_vars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112aaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = var_df[~var_df[\"var_name\"].isin(clm_related_vars)]\n",
    "var_df = var_df[~var_df[\"var_name\"].isin(eucalc_transpor_related_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_df = var_df[var_df[\"var_name\"].isin([\"industrial or commercial units cover\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df = gpd.read_file(os.path.join(SHP_PATH, \"LAU.shp\"))\n",
    "regions_df[\"country\"] = regions_df[\"prnt_code\"].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65213e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = '\\n'\n",
    "latex_nl = '\\\\\\\\'\n",
    "esc_nl = '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {'begin{tabular}': 'begin{tabularx}{\\\\textwidth}',\n",
    "                'end{tabular}': 'end{tabularx}',\n",
    "                 \"& 0 \\\\\\\\\": \"\",\n",
    "                \"_\": \"\\_\",\n",
    "                '\\\\\\\\': '\\\\\\\\\\midrule',\n",
    "                \"{\\\\textwidth}{| X | X |}\\n\": \"{\\\\textwidth}{| X | X |}\\n\\midrule\"\n",
    "\n",
    "               }\n",
    "\n",
    "def get_latex_table(df):\n",
    "    # prepare column_format\n",
    "    col_format = \"| X |\"\n",
    "    for i in range(len(df.columns)):\n",
    "        col_format = f\"{col_format} X |\"\n",
    "    \n",
    "    # pd to latex\n",
    "    table = df.style.to_latex(column_format=col_format, \n",
    "                                             position_float=\"centering\",\n",
    "                                             hrules=False,\n",
    "                                             environment = \"table*\", \n",
    "                                             position=\"h\"\n",
    "                                             )\n",
    "    # replace tabular with tabularx and add width=textwidth\n",
    "    for key, value in replacements.items():\n",
    "        table = table.replace(key, value)\n",
    "        \n",
    "    return table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7285d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country_code in [\"DE\", \"PL\", \"ES\"]:\n",
    "\n",
    "    for var_name in var_df[\"var_name\"]:\n",
    "        \n",
    "        data_df = pd.read_csv(os.path.join(DATA_PATH, f\"{country_code}_{var_name}.csv\"))\n",
    "        \n",
    "        if len(data_df) != 0: # vars present in only one country have a df with 0 rows . need to do something about this in the API\n",
    "            save_var_name = f\"{var_name[0].upper()}{var_name[1:]}\"\n",
    "              \n",
    "            var_metadata = client.get_variable_metadata(api_key=api_key,\n",
    "                                                    variable_name=var_name,\n",
    "                                                    country_code=country_code,\n",
    "                                                       spatial_resolution=\"LAU\")\n",
    "            \n",
    "        \n",
    "            var_unit = var_metadata[\"var_unit\"]\n",
    "            org_res = data_df[\"original_resolution\"].unique().item()\n",
    "            var_description = var_metadata[\"var_description\"]\n",
    "            data_years = list(data_df[\"year\"].unique())\n",
    "            data_source = data_df[\"data_source_name\"].unique().item()\n",
    "        \n",
    "            # table \n",
    "            table_dict = {\"Unit of measure\": var_unit, \n",
    "                    \"Original resolution\": org_res,\n",
    "                          }\n",
    "\n",
    "            if isinstance(data_years[0], np.int64):\n",
    "                data_years_neat = \", \".join([str(i) for i in data_years])\n",
    "                table_dict.update({'Data years': data_years_neat})\n",
    "            else:\n",
    "                table_dict.update({'Data years': \"No year\"})\n",
    "                \n",
    "            table_dict.update({'Data source': data_source}) #TODO: multirow with data source name, link and citation??  \n",
    "\n",
    "            if var_description is not None:\n",
    "                table_dict.update({\"Variable description\": var_description})\n",
    "\n",
    "            if org_res == \"LAU\":\n",
    "                table_dict.update({\"Further disaggregated?\": \"No\"})\n",
    "            \n",
    "            else:\n",
    "                proxies = []\n",
    "                for proxy_dict in var_metadata[\"proxy_metrics\"]:\n",
    "                    proxies.append(proxy_dict[\"var_name\"])\n",
    "                    \n",
    "                if proxies == []:\n",
    "                    table_dict.update({\"Further disaggregated?\": \"Yes\"})\n",
    "                    table_dict.update({\"Disaggregation method\": \"Same value as parent region to its LAU regions\"})\n",
    "                \n",
    "                else:\n",
    "                    proxy_neat = \", \".join(proxies)\n",
    "                    \n",
    "                    table_dict.update({\"Further disaggregated?\": \"Yes\"})\n",
    "                    table_dict.update({\"Disaggregation method\": \"Using proxy variables\"})\n",
    "                    table_dict.update({\"Proxy variables\": proxy_neat})\n",
    "                \n",
    "            table = pd.DataFrame.from_dict(table_dict, orient=\"index\")\n",
    "            with open(os.path.join(REPORT_PATH,  \"tables\", f\"{save_var_name}_{country_code}.tex\"), \"w\") as f:\n",
    "\n",
    "                latex_table = get_latex_table(table)\n",
    "                f.write(latex_table)\n",
    "                f.write(nl)\n",
    "\n",
    "            # figure 1: distribution plot =============================================================================\n",
    "\n",
    "            fig = plt.figure(figsize=(13, 5))\n",
    "            gs = fig.add_gridspec(1, 2, wspace=0.3, hspace=0)\n",
    "\n",
    "            # distribution - boxplot -------\n",
    "            ax1 = plt.subplot(gs[:, :1])\n",
    "\n",
    "            _data = data_df.loc[data_df[\"quality_rating\"] == \"good\", \"value\"].values # only showing \"good\" values\n",
    "            sns.boxplot(y= _data,\n",
    "                        width=0.3, ax=ax1)\n",
    "\n",
    "            ax1.set_xlabel(\"\")\n",
    "            ax1.set_ylabel(f\"[{var_unit}]\", fontsize=17)\n",
    "            ax1.tick_params(labelsize=15)\n",
    "\n",
    "            ax1.tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False) # labels along the bottom edge are off\n",
    "\n",
    "            # missing values - barplot --------\n",
    "            ax2 = plt.subplot(gs[:, 1:])\n",
    "\n",
    "            n_good = len(data_df[data_df[\"quality_rating\"] == \"good\"])\n",
    "            n_bad = len(data_df[data_df[\"quality_rating\"] == \"bad\"])\n",
    "\n",
    "            ax2.bar(x=[0, 1, 2], height=[n_good, 0, 0], width=0.5, color='green', label='present')\n",
    "            ax2.bar(x=[0, 1, 2], height=[n_bad, 0, 0], bottom=n_good, width=0.5, color='red', label='missing')\n",
    "\n",
    "            ax2.tick_params(labelsize=13)\n",
    "            ax2.tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False) # labels along the bottom edge are off\n",
    "\n",
    "            ax2.set_ylabel('[number of regions]', fontsize=17)\n",
    "            ax2.set_ylim([0, len(data_df)+500])\n",
    "\n",
    "            ax2.tick_params(labelsize=15)\n",
    "\n",
    "            ax2.set_axisbelow(True)\n",
    "            ax2.yaxis.grid(color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "            ax2.legend(borderpad=1, loc=\"upper right\", fontsize=15)\n",
    "\n",
    "            plt.savefig(os.path.join(REPORT_PATH, \n",
    "                                     \"figures\", \n",
    "                                     f\"{var_name[0].upper()}{var_name[1:]}_{country_code}.png\"),\n",
    "                       format='png', bbox_inches=\"tight\", dpi=200)\n",
    "\n",
    "            # figure 2: maps =============================================================================\n",
    "            # sometimes there is a mismatch between types. donno why!\n",
    "            country_regions_df = regions_df[regions_df[\"country\"] == country_code]\n",
    "\n",
    "            fixed_code_len = len(country_regions_df[\"code\"].values[0])\n",
    "            data_df['region_code'] = data_df['region_code'].astype(str) \n",
    "            data_df['region_code'] = data_df['region_code'].str.zfill(fixed_code_len)\n",
    "\n",
    "            _sub_df = pd.merge(country_regions_df, \n",
    "                               data_df, \n",
    "                               left_on=\"code\", \n",
    "                               right_on=\"region_code\", \n",
    "                               how=\"left\")\n",
    "\n",
    "            # distribution --------\n",
    "            fig = plt.figure(figsize=(13, 13))\n",
    "            gs = fig.add_gridspec(1, 2, wspace=0.1, hspace=0)\n",
    "\n",
    "            ax1 = plt.subplot(gs[:, :1])\n",
    "\n",
    "            vmin, vmax = min(_sub_df['value']), max(_sub_df['value'])\n",
    "            _sub_df.plot(column='value', cmap='Blues', linewidth=0.8, ax=ax1, edgecolor='none')\n",
    "            ax1.axis('off')\n",
    "\n",
    "            sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "            sm._A = []\n",
    "            axins = inset_axes(ax1,\n",
    "                        width=\"90%\",  \n",
    "                        height=\"5%\",\n",
    "                        loc='lower center',\n",
    "                        borderpad=-2\n",
    "                       )\n",
    "            clb = fig.colorbar(sm, cax=axins, orientation=\"horizontal\", shrink=0.8)\n",
    "            clb.ax.tick_params(labelsize=15)\n",
    "            clb.ax.set_title(f\"[{var_unit}]\", fontsize=15)\n",
    "            # missing values --------\n",
    "            ax2 = plt.subplot(gs[:, 1:])\n",
    "\n",
    "            col_dict = {\"good\": \"green\", \"bad\": \"red\"}\n",
    "            map_dict = {\"good\": \"present\", \"bad\": \"missing\"}\n",
    "            for key, group in _sub_df.groupby(\"quality_rating\"): \n",
    "                group.replace({\"quality_rating\": key})\n",
    "                group.plot(column='quality_rating', \n",
    "                           color=col_dict[key], \n",
    "                           edgecolor=col_dict[key],\n",
    "                           ax=ax2)\n",
    "\n",
    "            handles = []\n",
    "            for col, color in col_dict.items():\n",
    "                patch = mpatches.Patch(color=color, label=map_dict[col])\n",
    "                handles.append(patch)\n",
    "\n",
    "            plt.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, 0), ncol=2, fontsize=15)\n",
    "\n",
    "            ax2.axis('off')\n",
    "\n",
    "            plt.savefig(os.path.join(REPORT_PATH, \n",
    "                                     \"figures\", \n",
    "                                     f\"{save_var_name}_{country_code}_map.png\"),\n",
    "                       format='png', bbox_inches=\"tight\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vars are currently not in the API\n",
    "var_df = var_df[~var_df[\"var_name\"].isin([\n",
    "                                        \"land use - no data cover\",\n",
    "    \"waste from other sources - glass\"\n",
    "\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021cb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for latex report - segregate between common var and country-specific vars \n",
    "common_vars = []\n",
    "de_extra_vars = []\n",
    "pl_extra_vars = []\n",
    "for var_name in var_df[\"var_name\"]:\n",
    "    save_var_name = f\"{var_name[0].upper()}{var_name[1:]}\"\n",
    "    \n",
    "    de_df = pd.read_csv(os.path.join(DATA_PATH, f\"DE_{var_name}.csv\"))\n",
    "    pl_df = pd.read_csv(os.path.join(DATA_PATH, f\"PL_{var_name}.csv\"))\n",
    "    es_df = pd.read_csv(os.path.join(DATA_PATH, f\"ES_{var_name}.csv\"))\n",
    "    \n",
    "    if len(es_df) != 0:\n",
    "        common_vars.append(save_var_name)\n",
    "    elif len(pl_df) > 0:\n",
    "        pl_extra_vars.append(save_var_name)    \n",
    "    elif len(de_df) > 0:\n",
    "        de_extra_vars.append(save_var_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('common_vars.txt', 'w') as f:\n",
    "    neat_str = \", \".join(common_vars)\n",
    "    neat_str = neat_str.replace(\"_\", \"\\_\")\n",
    "    f.write(neat_str)\n",
    "    \n",
    "with open('pl_extra_vars.txt', 'w') as f:\n",
    "    neat_str = \", \".join(pl_extra_vars)\n",
    "    neat_str = neat_str.replace(\"_\", \"\\_\")\n",
    "    f.write(neat_str)\n",
    "    \n",
    "with open('de_extra_vars.txt', 'w') as f:\n",
    "    neat_str = \", \".join(de_extra_vars)\n",
    "    neat_str = neat_str.replace(\"_\", \"\\_\")\n",
    "    f.write(neat_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee3411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
